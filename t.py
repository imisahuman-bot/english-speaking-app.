import streamlit as st
import sounddevice as sd
import numpy as np
import tempfile
import whisper
import difflib
import pyttsx3
import time
import soundfile as sf

# ===============================
# 1. Cache Whisper model (load 1 l·∫ßn)
# ===============================
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("tiny")  # d√πng tiny cho nhanh

model = load_whisper_model()

# ===============================
# 2. H√†m ghi √¢m
# ===============================
def record_audio(duration=5, fs=16000):
    st.info("üé§ ƒêang ghi √¢m... N√≥i ƒëi b·∫°n!")
    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype="float32")
    sd.wait()
    st.success("‚úÖ Ghi √¢m xong!")
    return np.squeeze(recording)

# ===============================
# 3. Ch·∫•m ƒëi·ªÉm ph√°t √¢m (so s√°nh v·ªõi IPA/t·ª´ g·ªëc)
# ===============================
def check_pronunciation(user_text, target_word):
    ratio = difflib.SequenceMatcher(None, user_text.lower(), target_word.lower()).ratio()
    return ratio

# ===============================
# 4. ƒê·ªçc to t·ª´ v·ª±ng
# ===============================
def speak_word(word):
    engine = pyttsx3.init()
    engine.say(word)
    engine.runAndWait()

# ===============================
# 5. Streamlit UI
# ===============================
def main():
    st.title("üìö Luy·ªán ph√°t √¢m t·ª´ v·ª±ng")
    st.write("N√≥i theo t·ª´ h·ªá th·ªëng ƒë∆∞a ra, r·ªìi ki·ªÉm tra ƒë√∫ng sai üöÄ")

    # T·ª´ v·ª±ng m·∫´u
    vocab = {
        "apple": {"mean": "qu·∫£ t√°o", "ipa": "/Àà√¶p.lÃ©/"},
        "banana": {"mean": "qu·∫£ chu·ªëi", "ipa": "/b…ôÀàn…ëÀê.n…ô/"},
        "orange": {"mean": "qu·∫£ cam", "ipa": "/Àà…ír.…™nd í/"}
    }

    word = st.selectbox("Ch·ªçn t·ª´ ƒë·ªÉ luy·ªán:", list(vocab.keys()))
    st.write(f"**Nghƒ©a:** {vocab[word]['mean']}")
    st.write(f"**IPA:** {vocab[word]['ipa']}")

    if st.button("üîä Nghe ph√°t √¢m"):
        speak_word(word)

    if st.button("üéô Ghi √¢m & Ki·ªÉm tra"):
        audio = record_audio()

        # L∆∞u t·∫°m file wav
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
            sf.write(tmpfile.name, audio, 16000)
            file_path = tmpfile.name

        # Nh·∫≠n di·ªán b·∫±ng Whisper
        result = model.transcribe(file_path, fp16=False, language="en")
        user_text = result["text"].strip()

        st.write(f"üó£ B·∫°n n√≥i: `{user_text}`")

        # ƒê√°nh gi√° ƒë√∫ng sai
        score = check_pronunciation(user_text, word)
        if score > 0.8:
            st.success(f"‚úÖ Chu·∫©n r·ªìi! ({score*100:.1f}%)")
        else:
            st.error(f"‚ùå Ch∆∞a chu·∫©n l·∫Øm ({score*100:.1f}%)")

if __name__ == "__main__":
    main()
